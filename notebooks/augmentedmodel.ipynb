{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "\n",
    "## Data processing pipeline\n",
    "\n",
    "- option to use preprocess_input functions from [keras.applications](https://keras.io/api/applications/) (so the images preprocessing matches the one used for imagenet training, apparently [this is not done automatically by keras_unet_collection](https://github.com/yingkaisha/keras-unet-collection/issues/29))\n",
    "- option to output one-hot encoded masks (to be used with CategoricalFocalCrossentropy and other losses that require it)\n",
    "- optional caching\n",
    "\n",
    "\n",
    "## Custom AugmentedSegmentationModel model\n",
    "\n",
    "- Augmentations are computed by the GPU before passing them to the segmentation model\n",
    "\n",
    "## Training\n",
    "\n",
    "- Added the keras IoU (jaccard) metric, wich allows to compute the metric for each class independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 11:29:08.502567: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-18 11:29:08.512951: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-18 11:29:08.516126: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-18 11:29:08.524823: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:   GPU is not detected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 11:29:11.628416: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-09-18 11:29:11.628434: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:135] retrieving CUDA diagnostic information for host: cb83da628e80\n",
      "2024-09-18 11:29:11.628439: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:142] hostname: cb83da628e80\n",
      "2024-09-18 11:29:11.628481: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:166] libcuda reported version is: 550.107.2\n",
      "2024-09-18 11:29:11.628495: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:170] kernel reported version is: 550.107.2\n",
      "2024-09-18 11:29:11.628499: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:249] kernel version seems to match DSO: 550.107.2\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"GPU is detected.\")\n",
    "else:\n",
    "    print(\"WARNING:   GPU is not detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def binarize_mask(mask, threshold: int):\n",
    "    return tf.where(mask < threshold, tf.zeros_like(mask), tf.ones_like(mask))\n",
    "\n",
    "\n",
    "class GZ3DPipeline:\n",
    "    \"\"\"\n",
    "    A data pipeline class for preprocessing GZ3D datasets for machine learning models.\n",
    "    Attributes:\n",
    "        size (int): The target size for resizing images and masks.\n",
    "        mask_key (str): The key to access the mask in the dataset examples.\n",
    "        preprocess_input (callable, optional): A function to preprocess the input images (intended to be use with preprocess_input functions from keras.applications).\n",
    "        binary_threshold (int): Votes threshold used to binarize the mask.\n",
    "        sparce (bool): Whether to output a sparce or a one-hot encoded mask.\n",
    "        clip_votes_max (int): The maximum value to clip the mask votes.\n",
    "        batch_size (int): The batch size for the dataset.\n",
    "        shuffle_buffer_size (int): The buffer size for shuffling the dataset.\n",
    "        cache (bool): Whether to cache the dataset.\n",
    "        prefetch (bool): Whether to prefetch the dataset.\n",
    "    Methods:\n",
    "        load_data(example):\n",
    "            Loads and preprocesses the image and mask from a dataset example.\n",
    "        resize(image, mask):\n",
    "            Resizes the image and mask to the target size.\n",
    "        __call__(ds):\n",
    "            Applies the data pipeline to the given dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, mask_key=\"spiral_mask\", preprocess_input=None, binary_threshold=False, sparce=True, clip_votes_max=6, batch_size=32, shuffle_buffer_size=-1, cache=False, prefetch=False) -> None:\n",
    "        self.size = size\n",
    "        self.mask_key = mask_key\n",
    "        self.preprocess_input = preprocess_input\n",
    "        self.binary_threshold = binary_threshold\n",
    "        self.sparce = sparce\n",
    "        self.clip_votes_max = clip_votes_max\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle_buffer_size = shuffle_buffer_size\n",
    "        self.cache = cache\n",
    "        self.prefetch = prefetch\n",
    "\n",
    "\n",
    "    def load_data(self, example):\n",
    "        image = example[\"image\"]\n",
    "\n",
    "        if self.preprocess_input:\n",
    "            image = self.preprocess_input(image)\n",
    "        else:\n",
    "            image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "        mask = example[self.mask_key]\n",
    "\n",
    "        mask = tf.clip_by_value(mask, clip_value_min=0, clip_value_max=self.clip_votes_max)\n",
    "\n",
    "        if self.binary_threshold:\n",
    "            mask = binarize_mask(mask, self.binary_threshold)\n",
    "\n",
    "        if not self.sparce:\n",
    "            if self.binary_threshold:\n",
    "                num_classes = 2\n",
    "            else:\n",
    "                num_classes = 7\n",
    "\n",
    "            mask = tf.one_hot(tf.cast(mask, tf.int32), depth=num_classes)\n",
    "            mask = tf.squeeze(mask, axis=2)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def resize(self, image, mask):\n",
    "        image = tf.image.resize(image, (self.size, self.size))\n",
    "        mask = tf.image.resize(mask, (self.size, self.size))\n",
    "        return image, mask\n",
    "    \n",
    "    def __call__(self, ds):\n",
    "        ds = ds.map(self.load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        ds = ds.map(self.resize, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        if self.cache:\n",
    "            ds = ds.cache()\n",
    "        if self.shuffle_buffer_size > 0:\n",
    "            ds = ds.shuffle(buffer_size=self.shuffle_buffer_size)\n",
    "        ds = ds.batch(self.batch_size)\n",
    "        if self.prefetch:\n",
    "            ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "        return ds\n",
    "        \n",
    "\n",
    "class AugmentLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    A custom Keras layer for applying augmentations to both images and masks.\n",
    "    This layer ensures that the same augmentations are applied to both images and masks\n",
    "    during training. The augmentations are specified as a list of functions\n",
    "    Attributes:\n",
    "        augmentations (list): A list of augmentation functions or keras image augmentation layers to be applied to the images and masks.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, augmentations):\n",
    "        super(AugmentLayer, self).__init__()\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "    def call(self, images, masks, training=False):\n",
    "        # Apply the same augmentations to both images and masks during training\n",
    "        if training:\n",
    "            img_channels = tf.shape(images)[-1]\n",
    "            mask_channels = tf.shape(masks)[-1]\n",
    "            images_masks = tf.concat([images, masks], axis=-1)\n",
    "\n",
    "            for augmentation in self.augmentations:\n",
    "                images_masks = augmentation(images_masks)\n",
    "\n",
    "            images, masks = tf.split(images_masks, [img_channels, mask_channels], axis=-1)\n",
    "\n",
    "        return images, masks\n",
    "    \n",
    "\n",
    "class AugmentedSegmentationModel(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    A custom Keras model that integrates data augmentation with a segmentation model.\n",
    "    This model applies specified augmentations to both images and masks before passing\n",
    "    them to the segmentation model during training.\n",
    "\n",
    "    Attributes:\n",
    "        augment_layer (AugmentLayer): Layer that applies augmentations to images and masks.\n",
    "        segmentation_model (tf.keras.Model): The underlying segmentation model.\n",
    "    Methods:\n",
    "        call(inputs, training=False):\n",
    "            Forward pass of the model. Applies the segmentation model to the inputs.\n",
    "        train_step(data):\n",
    "            Custom training step that includes data augmentation and loss computation.\n",
    "            Args:\n",
    "                data (tuple): A tuple containing images and masks.\n",
    "            Returns:\n",
    "                dict: A dictionary containing the loss and other metrics.\n",
    "    \"\"\"\n",
    "    def __init__(self, augmentations, segmentation_model):\n",
    "        \"\"\"\n",
    "        Initializes the AugmentedSegmentationModel with the given augmentations and segmentation model.\n",
    "        Args:\n",
    "            augmentations (list): A list of augmentation functions or keras image augmentation layers to be applied to the images and masks.\n",
    "            segmentation_model: The segmentation model to be used for image segmentation.\n",
    "        \"\"\"\n",
    "\n",
    "        super(AugmentedSegmentationModel, self).__init__()\n",
    "        self.augment_layer = AugmentLayer(augmentations)  # Augmentation layer for both images and masks\n",
    "        self.segmentation_model = segmentation_model  # Segmentation model\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        return self.segmentation_model(inputs, training=training)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        images, masks = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            images, masks = self.augment_layer(images, masks, training=True)\n",
    "            predictions = self(images, training=True)\n",
    "            loss = self.compute_loss(y=masks, y_pred=predictions)\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        for metric in self.metrics:\n",
    "            if metric.name == \"loss\":\n",
    "                metric.update_state(loss)\n",
    "            else:\n",
    "                metric.update_state(masks, predictions)\n",
    "\n",
    "        # Return a dictionary with loss and all metrics\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet_collection import models, losses\n",
    "\n",
    "segmentation_model = models.att_unet_2d((128, 128, 3), filter_num=[64, 128, 256, 512, 1024], n_labels=2, \n",
    "                           stack_num_down=2, stack_num_up=2, activation='ReLU', \n",
    "                           atten_activation='ReLU', attention='add', output_activation='Sigmoid', \n",
    "                           batch_norm=True, pool=False, unpool=False, \n",
    "                           backbone='vgg16', weights=\"imagenet\", \n",
    "                           freeze_backbone=True, freeze_batch_norm=True, \n",
    "                           name='attunet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AugmentedSegmentationModel(\n",
    "    augmentations=[\n",
    "        tf.keras.layers.RandomFlip(mode=\"horizontal and vertical\", seed=101),\n",
    "        tf.keras.layers.RandomRotation(factor=(0, 1), seed=101),\n",
    "        tf.keras.layers.RandomZoom(height_factor=(-0.2, +0.2))\n",
    "    ],\n",
    "    segmentation_model=segmentation_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK = \"spiral_mask\"\n",
    "MIN_VOTE = 3\n",
    "STEPS_PER_EPOCH = 153\n",
    "VALIDATION_STEPS = 32\n",
    "NUM_EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = GZ3DPipeline(\n",
    "    size=128,\n",
    "    mask_key=MASK,\n",
    "    preprocess_input=preprocess_input,\n",
    "    binary_threshold=MIN_VOTE,\n",
    "    clip_votes_max=6,\n",
    "    sparce=False,\n",
    "    shuffle_buffer_size=1000,\n",
    "    cache=True,\n",
    "    prefetch=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_val, ds_test = tfds.load('galaxy_zoo3d', split=['train[:75%]', 'train[75%:90%]', 'train[90%:]'])\n",
    "\n",
    "ds_train = ds_train.filter(lambda x: tf.reduce_max(x[MASK]) >= MIN_VOTE)\n",
    "ds_val = ds_val.filter(lambda x: tf.reduce_max(x[MASK]) >= MIN_VOTE)\n",
    "ds_test = ds_test.filter(lambda x: tf.reduce_max(x[MASK]) >= MIN_VOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = pipeline(ds_train)\n",
    "val_batches = pipeline(ds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=tf.keras.losses.CategoricalFocalCrossentropy(\n",
    "      alpha=[0.25, 0.75],\n",
    "      gamma=0.1,\n",
    "      label_smoothing=0.25,\n",
    "      from_logits=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=loss,\n",
    "    # optimizer=tf.keras.optimizers.SGD(learning_rate=1e-1), \n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.IoU(num_classes=2, target_class_ids=[0], sparse_y_true=False, sparse_y_pred=False, name=\"IoU_0\"),\n",
    "        tf.keras.metrics.IoU(num_classes=2, target_class_ids=[1], sparse_y_true=False, sparse_y_pred=False, name=\"IoU_1\"),\n",
    "        tf.keras.metrics.MeanIoU(num_classes=2, sparse_y_true=False, sparse_y_pred=False, name=\"MeanIoU\"),\n",
    "        # jaccard,\n",
    "        # dice\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(\n",
    "    train_batches,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    # steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    # validation_steps=VALIDATION_STEPS,\n",
    "    validation_data=val_batches,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
